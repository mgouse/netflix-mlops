apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: netflix-ml-pipeline-
  namespace: argo
spec:
  entrypoint: ml-pipeline
  serviceAccountName: default

  # Volume sharing - Uses PVC to share data between steps
  volumeClaimTemplates:
  - metadata: 
      name: workdir
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources: 
        requests: 
          storage: 1Gi

  templates:
  - name: ml-pipeline
    dag:
      # Proper Dependencies - DAG structure ensures correct execution order
      tasks:
      - name: setup-feature-store
        template: setup-fs
      - name: fetch-features
        template: fetch-features
        dependencies: [setup-feature-store]
      - name: train-model
        template: train-model
        dependencies: [fetch-features]
      - name: evaluate-and-register
        template: evaluate-and-register
        dependencies: [train-model]

  # Feature Store Integration - Added SQLite-based feature store 
  # (production systems often use Feast or Tecton)
  - name: setup-fs
    container:
      image: python:3.9-slim  # Use slim image for efficiency
      command: [python, -c]
      args:
        - |
          import sqlite3, json
          print("Initializing Feature Store (SQLite)...")
          
          # Added pip install commands - Ensures dependencies are available
          import subprocess
          subprocess.run(["pip", "install", "pandas"], check=True)

          import pandas as pd
          conn = sqlite3.connect('/work/feature_store.db')
          
          # Enhanced feature store - Added more features including categorical data
          features_df = pd.DataFrame({
              'user_id': [f'user_{i}' for i in range(100)],
              'avg_rating': [round(3.5 + i/100, 2) for i in range(100)],
              'movies_watched': [10 + i for i in range(100)],
              'genre_preference': ['action' if i%3==0 else 'comedy' if i%3==1 else 'drama' for i in range(100)]
          })
          features_df.to_sql('user_features', conn, if_exists='replace', index=False)
          conn.close()
          
          # Metadata tracking - Saves JSON files for workflow tracking
          with open('/work/feature_metadata.json', 'w') as f:
              json.dump({'features': list(features_df.columns), 'count': len(features_df)}, f)
          
          print("✓ Feature Store initialized with 100 user records.")
      volumeMounts:
      - name: workdir
        mountPath: /work

  # Fetch features from store
  - name: fetch-features
    container:
      image: python:3.9-slim
      command: [python, -c]
      args:
        - |
          import sqlite3, json
          print("Fetching features from Feature Store...")

          # Added pip install commands
          import subprocess
          subprocess.run(["pip", "install", "pandas"], check=True)

          import pandas as pd
          conn = sqlite3.connect('/work/feature_store.db')
          df = pd.read_sql_query("SELECT * FROM user_features", conn)
          print(f"Fetched {len(df)} records")
          print("\nSample features:")
          print(df.head())

          # Save for training
          df.to_csv('/work/training_data.csv', index=False)
          conn.close()
          
          # Metadata tracking - Save stats for monitoring
          with open('/work/data_stats.json', 'w') as f:
              json.dump({
                  'total_records': len(df),
                  'features': list(df.columns),
                  'timestamp': pd.Timestamp.now().isoformat()
              }, f)
          
          print("✓ Features fetched and saved.")
      volumeMounts:
      - name: workdir
        mountPath: /work

  # Train and log to MLflow
  - name: train-model
    container:
      image: python:3.9
      command: [/bin/bash, -c]
      args:
        - |
          # Added pip install commands
          pip install mlflow==2.8.0 pandas scikit-learn
          
          python -c "
          import mlflow, pickle, pandas as pd, json
          from sklearn.ensemble import RandomForestRegressor
          from sklearn.model_selection import train_test_split
          from sklearn.metrics import mean_squared_error, r2_score

          print('Training model...')

          # MLflow Integration - Properly configured to use the in-cluster MLflow service
          mlflow.set_tracking_uri('http://mlflow-service.argo.svc.cluster.local:5000')
          mlflow.set_experiment('Netflix-Retraining-Pipeline')

          with mlflow.start_run() as run:
              df = pd.read_csv('/work/training_data.csv')
              X = df[['movies_watched', 'avg_rating']]
              y = df['avg_rating']

              # Proper train/test split - More realistic ML workflow
              X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

              # Log parameters
              mlflow.log_param('n_estimators', 50)
              mlflow.log_param('max_depth', 5)
              mlflow.log_param('train_size', len(X_train))
              mlflow.log_param('test_size', len(X_test))

              # Train model
              model = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=42)
              model.fit(X_train, y_train)

              # Evaluate
              y_pred = model.predict(X_test)
              mse = mean_squared_error(y_test, y_pred)
              r2 = r2_score(y_test, y_pred)

              # Multiple metrics - Added R2 score alongside MSE
              mlflow.log_metric('mse', mse)
              mlflow.log_metric('r2_score', r2)

              # Log model
              mlflow.sklearn.log_model(model, 'model')

              print(f'Model trained successfully!')
              print(f'MSE: {mse:.4f}')
              print(f'R2 Score: {r2:.4f}')
              print(f'Run ID: {run.info.run_id}')

              # Metadata tracking
              with open('/work/run_info.json', 'w') as f:
                  json.dump({'run_id': run.info.run_id, 'mse': mse, 'r2_score': r2}, f)
          "
      volumeMounts:
      - name: workdir
        mountPath: /work

  # Evaluate and conditionally register
  - name: evaluate-and-register
    container:
      image: python:3.9
      command: [/bin/bash, -c]
      args:
        - |
          pip install mlflow==2.8.0 pandas

          python -c "
          import mlflow, json
          from mlflow.tracking import MlflowClient

          print('Evaluating and registering model...')

          mlflow.set_tracking_uri('http://mlflow-service.argo.svc.cluster.local:5000')
          client = MlflowClient()

          with open('/work/run_info.json', 'r') as f:
              run_info = json.load(f)

          run_id = run_info['run_id']
          mse = run_info['mse']
          r2_score = run_info['r2_score']

          print(f'Model Performance:')
          print(f'  MSE: {mse:.4f}')
          print(f'  R2 Score: {r2_score:.4f}')

          # Model Registry - Implements conditional model registration based on performance
          MSE_THRESHOLD = 0.15
          R2_THRESHOLD = 0.7

          if mse < MSE_THRESHOLD and r2_score > R2_THRESHOLD:
              print('✓ Model performance meets criteria. Registering model...')
              model_uri = f'runs:/{run_id}/model'
              model_version = mlflow.register_model(model_uri, 'netflix-recommender')

              # Model staging - Transitions model to staging (production-like pattern)
              client.transition_model_version_stage(
                  name='netflix-recommender',
                  version=model_version.version,
                  stage='Staging'
              )

              print(f'✓ Model registered as version {model_version.version}')

              # Metadata tracking
              with open('/work/deployment_decision.json', 'w') as f:
                  json.dump({
                      'deploy': True,
                      'model_version': model_version.version,
                      'metrics': {'mse': mse, 'r2_score': r2_score}
                  }, f)
          else:
              print('✗ Model performance below threshold. Not registering.')
              with open('/work/deployment_decision.json', 'w') as f:
                  json.dump({
                      'deploy': False,
                      'reason': 'Performance below threshold',
                      'metrics': {'mse': mse, 'r2_score': r2_score}
                  }, f)
          "
      volumeMounts:
      - name: workdir
        mountPath: /work
