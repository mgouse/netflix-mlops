apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: netflix-ml-prod-
  namespace: argo
spec:
  entrypoint: ml-pipeline
  serviceAccountName: default
  
  # Shared volume for passing data between steps
  volumeClaimTemplates:
  - metadata:
      name: workdir
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 1Gi
  
  templates:
  - name: ml-pipeline
    dag:
      tasks:
      - name: fetch-data
        template: fetch-netflix-data
      - name: preprocess
        template: preprocess-data
        dependencies: [fetch-data]
      - name: train-model
        template: train-knn-model
        dependencies: [preprocess]
      - name: evaluate
        template: evaluate-model
        dependencies: [train-model]
      - name: deploy-decision
        template: deployment-decision
        dependencies: [evaluate]

  - name: fetch-netflix-data
    container:
      image: python:3.9
      command: [python, -c]
      args:
        - |
          import json
          import random
          from datetime import datetime
          
          print(f"[{datetime.now()}] Fetching Netflix data...")
          
          # Simulate data fetching
          data_stats = {
              "total_users": 50000,
              "total_movies": 10000,
              "total_ratings": random.randint(900000, 1100000),
              "fetch_time": datetime.now().isoformat(),
              "data_quality": "PASS"
          }
          
          print(f"Fetched {data_stats['total_ratings']} ratings")
          print(f"Users: {data_stats['total_users']}")
          print(f"Movies: {data_stats['total_movies']}")
          
          # Save stats
          with open('/work/data_stats.json', 'w') as f:
              json.dump(data_stats, f)
          
          print("âœ… Data fetch completed")
      volumeMounts:
      - name: workdir
        mountPath: /work

  - name: preprocess-data
    container:
      image: python:3.9
      command: [python, -c]
      args:
        - |
          import json
          from datetime import datetime
          
          print(f"[{datetime.now()}] Preprocessing data...")
          
          # Load data stats
          with open('/work/data_stats.json', 'r') as f:
              stats = json.load(f)
          
          print(f"Processing {stats['total_ratings']} ratings...")
          
          # Simulate preprocessing
          processed_stats = {
              **stats,
              "features_extracted": 128,
              "null_values_removed": 1523,
              "duplicates_removed": 342,
              "preprocessing_time": "45 seconds"
          }
          
          with open('/work/processed_stats.json', 'w') as f:
              json.dump(processed_stats, f)
          
          print("âœ… Preprocessing completed")
      volumeMounts:
      - name: workdir
        mountPath: /work

  - name: train-knn-model
    container:
      image: python:3.9
      command: [python, -c]
      args:
        - |
          import json
          import random
          from datetime import datetime
          
          print(f"[{datetime.now()}] Training KNN model...")
          
          # Load processed stats
          with open('/work/processed_stats.json', 'r') as f:
              stats = json.load(f)
          
          print(f"Training on {stats['total_users']} users")
          print("Model: KNN with n_neighbors=15")
          
          # Simulate training
          for epoch in range(3):
              print(f"Epoch {epoch+1}/3...")
          
          # Generate metrics
          model_metrics = {
              "model_type": "KNN",
              "n_neighbors": 15,
              "training_time": "2 minutes 34 seconds",
              "model_size_mb": 45.2,
              "timestamp": datetime.now().isoformat()
          }
          
          with open('/work/model_info.json', 'w') as f:
              json.dump(model_metrics, f)
          
          print("âœ… Model training completed")
      volumeMounts:
      - name: workdir
        mountPath: /work

  - name: evaluate-model
    container:
      image: python:3.9
      command: [python, -c]
      args:
        - |
          import json
          import random
          from datetime import datetime
          
          print(f"[{datetime.now()}] Evaluating model...")
          
          # Simulate evaluation
          metrics = {
              "accuracy": round(random.uniform(0.88, 0.94), 3),
              "precision": round(random.uniform(0.85, 0.92), 3),
              "recall": round(random.uniform(0.82, 0.90), 3),
              "f1_score": round(random.uniform(0.84, 0.91), 3),
              "coverage": round(random.uniform(0.42, 0.48), 3),
              "latency_ms": round(random.uniform(12, 25), 1),
              "evaluation_time": datetime.now().isoformat()
          }
          
          print(f"Accuracy: {metrics['accuracy']}")
          print(f"Precision: {metrics['precision']}")
          print(f"Recall: {metrics['recall']}")
          print(f"F1 Score: {metrics['f1_score']}")
          print(f"Coverage: {metrics['coverage']}")
          print(f"Latency: {metrics['latency_ms']}ms")
          
          with open('/work/evaluation_metrics.json', 'w') as f:
              json.dump(metrics, f)
          
          print("âœ… Evaluation completed")
      volumeMounts:
      - name: workdir
        mountPath: /work

  - name: deployment-decision
    container:
      image: python:3.9
      command: [python, -c]
      args:
        - |
          import json
          from datetime import datetime
          
          print(f"[{datetime.now()}] Making deployment decision...")
          
          # Load metrics
          with open('/work/evaluation_metrics.json', 'r') as f:
              metrics = json.load(f)
          
          print("\nðŸ“Š Model Performance Summary:")
          print(f"   Accuracy: {metrics['accuracy']}")
          print(f"   Latency: {metrics['latency_ms']}ms")
          
          # Decision logic
          if metrics['accuracy'] > 0.85 and metrics['latency_ms'] < 50:
              print("\nâœ… APPROVED FOR DEPLOYMENT")
              print("   Model meets all criteria")
              print("   Deployment command:")
              print("   kubectl set image deployment/netflix-api netflix-api=netflix-api:v2.0 -n netflix-ml")
              
              decision = {
                  "approved": True,
                  "reason": "Meets performance criteria",
                  "metrics": metrics,
                  "timestamp": datetime.now().isoformat()
              }
          else:
              print("\nâŒ DEPLOYMENT REJECTED")
              print("   Model does not meet criteria")
              decision = {
                  "approved": False,
                  "reason": "Performance below threshold",
                  "metrics": metrics,
                  "timestamp": datetime.now().isoformat()
              }
          
          with open('/work/deployment_decision.json', 'w') as f:
              json.dump(decision, f, indent=2)
          
          print("\nðŸ“ Decision logged")
      volumeMounts:
      - name: workdir
        mountPath: /work